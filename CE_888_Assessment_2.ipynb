{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JJEEEFFFF/CE-888-Assignment-2/blob/main/CE_888_Assessment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**CE-888 Assignment-2 seq to SQL **\n",
        "Importing the required Libraries "
      ],
      "metadata": {
        "id": "CVCKCLW6t4ou"
      },
      "id": "CVCKCLW6t4ou"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27063a6c"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "import json\n",
        "import pathlib\n",
        "import random\n",
        "import string\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "from tensorflow.keras.layers import TextVectorization\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "id": "27063a6c"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing the Dataset in colab"
      ],
      "metadata": {
        "id": "3780FB4Bu9I1"
      },
      "id": "3780FB4Bu9I1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "aNN-9Gdds7bB",
        "outputId": "bbbbef4a-742e-4405-a545-e7f1ef5b86a5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-577fcd31-3062-4bc8-b1b6-2cfab445f24e\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-577fcd31-3062-4bc8-b1b6-2cfab445f24e\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train_others.json to train_others.json\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e358e595-3789-47e1-8fcd-5f66a80aa6c0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e358e595-3789-47e1-8fcd-5f66a80aa6c0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train_spider.json to train_spider.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "Spider_dataset_1=files.upload()\n",
        "Spider_dataset_2=files.upload()"
      ],
      "id": "aNN-9Gdds7bB"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xqgnQlANuiBC"
      },
      "source": [
        "\n",
        "Retrieveing the Datasets"
      ],
      "id": "xqgnQlANuiBC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umSPHddViHpH"
      },
      "outputs": [],
      "source": [
        "train_path = '/content/train_others.json'\n",
        "train_other_path = '/content/train_spider.json'\n",
        "\n",
        "\n",
        "train_data = pd.read_json(train_path)\n",
        "train_other_data = pd.read_json(train_other_path)\n",
        "\n",
        "train_data = train_data.head(1000)\n",
        "train_other_data = train_other_data.head(1000)"
      ],
      "id": "umSPHddViHpH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEQM0sK-ulF4"
      },
      "source": [
        "**Concatenate Datasets**"
      ],
      "id": "VEQM0sK-ulF4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "ZWmhjJWeuJ3d",
        "outputId": "2b7b5595-e14c-40fd-a835-f5529138c139"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  db_id                                              query  \\\n",
              "0   geo  SELECT city_name FROM city WHERE population  =...   \n",
              "1   geo  SELECT city_name FROM city WHERE population  =...   \n",
              "2   geo  SELECT city_name FROM city WHERE population  =...   \n",
              "3   geo  SELECT city_name FROM city WHERE population  =...   \n",
              "4   geo  SELECT city_name FROM city WHERE population  =...   \n",
              "\n",
              "                                          query_toks  \\\n",
              "0  [SELECT, city_name, FROM, city, WHERE, populat...   \n",
              "1  [SELECT, city_name, FROM, city, WHERE, populat...   \n",
              "2  [SELECT, city_name, FROM, city, WHERE, populat...   \n",
              "3  [SELECT, city_name, FROM, city, WHERE, populat...   \n",
              "4  [SELECT, city_name, FROM, city, WHERE, populat...   \n",
              "\n",
              "                                 query_toks_no_value  \\\n",
              "0  [select, city_name, from, city, where, populat...   \n",
              "1  [select, city_name, from, city, where, populat...   \n",
              "2  [select, city_name, from, city, where, populat...   \n",
              "3  [select, city_name, from, city, where, populat...   \n",
              "4  [select, city_name, from, city, where, populat...   \n",
              "\n",
              "                                           question  \\\n",
              "0               what is the biggest city in wyoming   \n",
              "1      what wyoming city has the largest population   \n",
              "2               what is the largest city in wyoming   \n",
              "3       where is the most populated area of wyoming   \n",
              "4  which city in wyoming has the largest population   \n",
              "\n",
              "                                       question_toks  \\\n",
              "0        [what, is, the, biggest, city, in, wyoming]   \n",
              "1  [what, wyoming, city, has, the, largest, popul...   \n",
              "2        [what, is, the, largest, city, in, wyoming]   \n",
              "3  [where, is, the, most, populated, area, of, wy...   \n",
              "4  [which, city, in, wyoming, has, the, largest, ...   \n",
              "\n",
              "                                                 sql  \n",
              "0  {'from': {'table_units': [['table_unit', 1]], ...  \n",
              "1  {'from': {'table_units': [['table_unit', 1]], ...  \n",
              "2  {'from': {'table_units': [['table_unit', 1]], ...  \n",
              "3  {'from': {'table_units': [['table_unit', 1]], ...  \n",
              "4  {'from': {'table_units': [['table_unit', 1]], ...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a70709a-7ff5-4c04-b0bc-99ba8927c6ec\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>db_id</th>\n",
              "      <th>query</th>\n",
              "      <th>query_toks</th>\n",
              "      <th>query_toks_no_value</th>\n",
              "      <th>question</th>\n",
              "      <th>question_toks</th>\n",
              "      <th>sql</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>geo</td>\n",
              "      <td>SELECT city_name FROM city WHERE population  =...</td>\n",
              "      <td>[SELECT, city_name, FROM, city, WHERE, populat...</td>\n",
              "      <td>[select, city_name, from, city, where, populat...</td>\n",
              "      <td>what is the biggest city in wyoming</td>\n",
              "      <td>[what, is, the, biggest, city, in, wyoming]</td>\n",
              "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>geo</td>\n",
              "      <td>SELECT city_name FROM city WHERE population  =...</td>\n",
              "      <td>[SELECT, city_name, FROM, city, WHERE, populat...</td>\n",
              "      <td>[select, city_name, from, city, where, populat...</td>\n",
              "      <td>what wyoming city has the largest population</td>\n",
              "      <td>[what, wyoming, city, has, the, largest, popul...</td>\n",
              "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>geo</td>\n",
              "      <td>SELECT city_name FROM city WHERE population  =...</td>\n",
              "      <td>[SELECT, city_name, FROM, city, WHERE, populat...</td>\n",
              "      <td>[select, city_name, from, city, where, populat...</td>\n",
              "      <td>what is the largest city in wyoming</td>\n",
              "      <td>[what, is, the, largest, city, in, wyoming]</td>\n",
              "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>geo</td>\n",
              "      <td>SELECT city_name FROM city WHERE population  =...</td>\n",
              "      <td>[SELECT, city_name, FROM, city, WHERE, populat...</td>\n",
              "      <td>[select, city_name, from, city, where, populat...</td>\n",
              "      <td>where is the most populated area of wyoming</td>\n",
              "      <td>[where, is, the, most, populated, area, of, wy...</td>\n",
              "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>geo</td>\n",
              "      <td>SELECT city_name FROM city WHERE population  =...</td>\n",
              "      <td>[SELECT, city_name, FROM, city, WHERE, populat...</td>\n",
              "      <td>[select, city_name, from, city, where, populat...</td>\n",
              "      <td>which city in wyoming has the largest population</td>\n",
              "      <td>[which, city, in, wyoming, has, the, largest, ...</td>\n",
              "      <td>{'from': {'table_units': [['table_unit', 1]], ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a70709a-7ff5-4c04-b0bc-99ba8927c6ec')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7a70709a-7ff5-4c04-b0bc-99ba8927c6ec button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7a70709a-7ff5-4c04-b0bc-99ba8927c6ec');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "train_data = pd.concat([train_data, train_other_data], axis=0, ignore_index=True)\n",
        "train_data.head()"
      ],
      "id": "ZWmhjJWeuJ3d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZaHBNxNuu0R"
      },
      "source": [
        "Creating  the List of 'Query' and 'Question' values from the dataset"
      ],
      "id": "UZaHBNxNuu0R"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZVwIzkhuwoK"
      },
      "outputs": [],
      "source": [
        "text_pairs = []\n",
        "for i in range (len(train_data)):\n",
        "    question=train_data.loc[i, \"question\"]\n",
        "    query=train_data.loc[i, \"query\"]\n",
        "    query = \"[start] \" + query + \" [end]\"\n",
        "    text_pairs.append((question, query))"
      ],
      "id": "EZVwIzkhuwoK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kHqd_r1vu7YH"
      },
      "source": [
        "Creating the Training, Testing & Validation Sets\n"
      ],
      "id": "kHqd_r1vu7YH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i2I8PhKpu8-d"
      },
      "outputs": [],
      "source": [
        "num_val_samples = int(0.15 * len(text_pairs))\n",
        "num_train_samples = len(text_pairs) - 2 * num_val_samples\n",
        "train_pairs = text_pairs[:num_train_samples]\n",
        "val_pairs = text_pairs[num_train_samples : num_train_samples + num_val_samples]\n",
        "test_pairs = text_pairs[num_train_samples + num_val_samples :]"
      ],
      "id": "i2I8PhKpu8-d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pH2c2dwvAxc",
        "outputId": "9a94499a-73a8-4f9f-da24-973a285fb3df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Training Pairs: 1400\n",
            "Total Testing Pairs: 300\n",
            "Total Validation Pairs: 300\n"
          ]
        }
      ],
      "source": [
        "print ('Total Training Pairs:', len(train_pairs))\n",
        "print ('Total Testing Pairs:', len(test_pairs))\n",
        "print ('Total Validation Pairs:', len(val_pairs))"
      ],
      "id": "4pH2c2dwvAxc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CR95lZi4vIXy"
      },
      "source": [
        "Performing Data Preprocessing that involves casefolding and Text Vectorizsation"
      ],
      "id": "CR95lZi4vIXy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqqE5AaTvD0G"
      },
      "outputs": [],
      "source": [
        "vocab_size = 15000\n",
        "sequence_length = 64\n",
        "batch_size = 128\n",
        "\n",
        "def custom_standardization(input_string):\n",
        "    lowercase = tf.strings.lower(input_string)\n",
        "    return lowercase\n",
        "\n",
        "question_vectorization = TextVectorization(max_tokens=vocab_size, output_mode=\"int\", output_sequence_length=sequence_length,)\n",
        "query_vectorization = TextVectorization(max_tokens=vocab_size,  output_mode=\"int\", output_sequence_length=sequence_length + 1, standardize=custom_standardization)\n"
      ],
      "id": "WqqE5AaTvD0G"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8oiM6JU1vI5e"
      },
      "outputs": [],
      "source": [
        "train_question_texts = [pair[0] for pair in train_pairs]\n",
        "train_query_texts = [pair[1] for pair in train_pairs]\n",
        "question_vectorization.adapt(train_question_texts)\n",
        "query_vectorization.adapt(train_query_texts)"
      ],
      "id": "8oiM6JU1vI5e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UH1hSvs_vRba"
      },
      "outputs": [],
      "source": [
        "def format_dataset(question, query):\n",
        "    question = question_vectorization(question)\n",
        "    query = query_vectorization(query)\n",
        "    return ({\"encoder_inputs\": question, \"decoder_inputs\": query[:, :-1],}, query[:, 1:])\n",
        "\n",
        "def make_dataset(pairs):\n",
        "    question_texts, query_texts = zip(*pairs)\n",
        "    question_texts = list(question_texts)\n",
        "    query_texts = list(query_texts)\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((question_texts, query_texts))\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.map(format_dataset)\n",
        "    return dataset.shuffle(2048).prefetch(16).cache()"
      ],
      "id": "UH1hSvs_vRba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FCvxWHHkv5zb"
      },
      "outputs": [],
      "source": [
        "train_ds = make_dataset(train_pairs)\n",
        "test_ds = make_dataset(test_pairs)\n",
        "val_ds = make_dataset(val_pairs)"
      ],
      "id": "FCvxWHHkv5zb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlnG01xKv7hA",
        "outputId": "ec8255a7-d09a-4e12-dab1-48dc254cf620"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inputs[\"encoder_inputs\"].shape: (128, 64)\n",
            "inputs[\"decoder_inputs\"].shape: (128, 64)\n",
            "targets.shape: (128, 64)\n"
          ]
        }
      ],
      "source": [
        "for inputs, targets in train_ds.take(1):\n",
        "    print(f'inputs[\"encoder_inputs\"].shape: {inputs[\"encoder_inputs\"].shape}')\n",
        "    print(f'inputs[\"decoder_inputs\"].shape: {inputs[\"decoder_inputs\"].shape}')\n",
        "    print(f\"targets.shape: {targets.shape}\")"
      ],
      "id": "wlnG01xKv7hA"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDuSr_1GwA-_"
      },
      "source": [
        "# Setting Parameters for the Embeddings"
      ],
      "id": "CDuSr_1GwA-_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X9RmEVsLv9j8"
      },
      "outputs": [],
      "source": [
        "embed_dim = 256\n",
        "latent_dim = 1024"
      ],
      "id": "X9RmEVsLv9j8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaYjMR3nwIQp"
      },
      "source": [
        "## Model 1: Single Layer Bidirectional GRU"
      ],
      "id": "ZaYjMR3nwIQp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XuvxiMeJwFRo"
      },
      "outputs": [],
      "source": [
        "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
        "encoded_source = layers.Bidirectional(layers.GRU(latent_dim), merge_mode=\"sum\")(x)"
      ],
      "id": "XuvxiMeJwFRo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lkq5QcyCwLmD"
      },
      "outputs": [],
      "source": [
        "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
        "decoder_gru = layers.GRU(latent_dim, return_sequences=True)\n",
        "x = decoder_gru(x, initial_state=encoded_source)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)"
      ],
      "id": "lkq5QcyCwLmD"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwfKr5d0wPVM"
      },
      "outputs": [],
      "source": [
        "seq2seq_01 = keras.Model([source, past_target], target_next_step)"
      ],
      "id": "fwfKr5d0wPVM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcUSaBnMwWt_"
      },
      "source": [
        "## Setup Callbacks"
      ],
      "id": "WcUSaBnMwWt_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VexHYtl1wWOg"
      },
      "outputs": [],
      "source": [
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=1),\n",
        "             ModelCheckpoint(\"seq2seq_01.keras\", save_best_only=True, monitor=\"val_accuracy\", mode='max')]"
      ],
      "id": "VexHYtl1wWOg"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tBEvFRuzwgBQ"
      },
      "source": [
        "## Compile and Run the model"
      ],
      "id": "tBEvFRuzwgBQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "phtGIYSywdol",
        "outputId": "534e8877-d30e-4fe5-8deb-e1be3244dced"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "11/11 [==============================] - 353s 31s/step - loss: 2.4581 - accuracy: 0.1006 - val_loss: 1.7839 - val_accuracy: 0.1713\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 337s 31s/step - loss: 1.6564 - accuracy: 0.1519 - val_loss: 1.8059 - val_accuracy: 0.2192\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 336s 31s/step - loss: 1.5252 - accuracy: 0.2030 - val_loss: 1.7847 - val_accuracy: 0.2603\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 347s 32s/step - loss: 1.3644 - accuracy: 0.2857 - val_loss: 1.7427 - val_accuracy: 0.3048\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 336s 31s/step - loss: 1.1273 - accuracy: 0.3973 - val_loss: 1.6861 - val_accuracy: 0.3398\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 339s 31s/step - loss: 0.9484 - accuracy: 0.4707 - val_loss: 1.5955 - val_accuracy: 0.3770\n",
            "Epoch 7/30\n",
            "11/11 [==============================] - 332s 30s/step - loss: 0.8163 - accuracy: 0.5242 - val_loss: 1.6079 - val_accuracy: 0.3945\n",
            "Epoch 8/30\n",
            "11/11 [==============================] - 335s 31s/step - loss: 0.7369 - accuracy: 0.5502 - val_loss: 1.5997 - val_accuracy: 0.3971\n",
            "Epoch 9/30\n",
            "11/11 [==============================] - 339s 31s/step - loss: 0.6779 - accuracy: 0.5743 - val_loss: 1.5671 - val_accuracy: 0.3829\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd0e193b8d0>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "seq2seq_01.compile(\n",
        "optimizer=\"rmsprop\",\n",
        "loss=\"sparse_categorical_crossentropy\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "seq2seq_01.fit(train_ds, epochs=30, validation_data=val_ds, callbacks=callbacks)"
      ],
      "id": "phtGIYSywdol"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5uOZH4UwkA2"
      },
      "outputs": [],
      "source": [
        "query_vocab = query_vectorization.get_vocabulary()\n",
        "query_index_lookup = dict(zip(range(len(query_vocab)), query_vocab))\n",
        "max_decoded_sentence_length = 20"
      ],
      "id": "u5uOZH4UwkA2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5lm4vRfnxIMZ"
      },
      "outputs": [],
      "source": [
        "def decode_sequence_01(input_sentence):\n",
        "  tokenized_input_sentence = question_vectorization([input_sentence])\n",
        "  decoded_sentence = \"[start]\"\n",
        "  for i in range(max_decoded_sentence_length):\n",
        "    tokenized_target_sentence = query_vectorization([decoded_sentence])\n",
        "    next_token_predictions = seq2seq_01.predict([tokenized_input_sentence, tokenized_target_sentence])\n",
        "    sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
        "\n",
        "    sampled_token = query_index_lookup[sampled_token_index]\n",
        "    decoded_sentence += \" \" + sampled_token\n",
        "    if sampled_token == \"[end]\":\n",
        "      break\n",
        "  return decoded_sentence"
      ],
      "id": "5lm4vRfnxIMZ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrp2yN9AxL6F",
        "outputId": "2c9979aa-308e-4d9f-d4bc-e350aba1225b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-1 Score on Test Dataset: 0.121104\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in test_pairs]\n",
        "query_texts = [pair[1] for pair in test_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_01(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Test Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "id": "xrp2yN9AxL6F"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a6zkofiPJXzz",
        "outputId": "36dce2c4-4897-443c-8769-30200d6878dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "What are distinct locations where tracks are located?\n",
            "[start] select state_name from river where state_name in ( select border from river where state_name in ( select border from border_info\n",
            "-\n",
            "What is the transaction type that has processed the greatest total amount in transactions?\n",
            "[start] select state_name from river where state_name in ( select border from river where state_name in ( select border from river\n",
            "-\n",
            "Find the policy type used by more than 4 customers.\n",
            "[start] select state_name from river where state_name in ( select border from river where state_name in ( select border from border_info\n",
            "-\n",
            "Show the enrollment and primary_conference of the oldest college.\n",
            "[start] select state_name from river where state_name in ( select border from river where state_name in ( select border from river\n",
            "-\n",
            "What is the product, chromosome, and porphyria of the enzymes located at 'Cytosol'?\n",
            "[start] select state_name from river where state_name in ( select border from river where state_name in ( select border from river\n"
          ]
        }
      ],
      "source": [
        "test_questions_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(5):\n",
        "  input_sentence = random.choice(test_questions_texts)\n",
        "  print(\"-\")\n",
        "  print(input_sentence)\n",
        "  print(decode_sequence_01(input_sentence))"
      ],
      "id": "a6zkofiPJXzz"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQEmukaJJgHY"
      },
      "source": [
        "# Compute BLEU Score on Validation Dataset"
      ],
      "id": "AQEmukaJJgHY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WKeCIpPyJc3Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4582a4ab-8f48-4142-f3be-b486d3449053"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-1 Score on Validation Dataset: 0.125224\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in val_pairs]\n",
        "query_texts = [pair[1] for pair in val_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_01(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Validation Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "id": "WKeCIpPyJc3Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j9ALpCK1Jph6"
      },
      "outputs": [],
      "source": [
        "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
        "out_encoder, state_h_forward, state_c_forward, state_h_backward, state_c_backward = layers.Bidirectional(layers.LSTM(latent_dim, return_sequences=True, return_state=True), merge_mode=\"sum\")(x)\n"
      ],
      "id": "j9ALpCK1Jph6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7uHKl2-Jq4I"
      },
      "outputs": [],
      "source": [
        "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
        "decoder_LSTM = layers.LSTM(latent_dim, return_sequences=True)\n",
        "\n",
        "encoder_state=[state_h_forward, state_c_forward]\n",
        "\n",
        "x = decoder_LSTM(x, initial_state=encoder_state)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)"
      ],
      "id": "z7uHKl2-Jq4I"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-Tc-BqgKIDf"
      },
      "outputs": [],
      "source": [
        "seq2seq_02 = keras.Model([source, past_target], target_next_step)"
      ],
      "id": "N-Tc-BqgKIDf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KxcXNA28KOU1"
      },
      "outputs": [],
      "source": [
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=1),\n",
        "             ModelCheckpoint(\"seq2seq_02.keras\", save_best_only=True, monitor=\"val_accuracy\", mode='max')]\n"
      ],
      "id": "KxcXNA28KOU1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9C3iAubxKS8Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69adf5c3-49fa-446f-8192-ae78f002e073"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['bidirectional_1/backward_lstm/lstm_cell_2/kernel:0', 'bidirectional_1/backward_lstm/lstm_cell_2/recurrent_kernel:0', 'bidirectional_1/backward_lstm/lstm_cell_2/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['bidirectional_1/backward_lstm/lstm_cell_2/kernel:0', 'bidirectional_1/backward_lstm/lstm_cell_2/recurrent_kernel:0', 'bidirectional_1/backward_lstm/lstm_cell_2/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "11/11 [==============================] - 341s 30s/step - loss: 2.3651 - accuracy: 0.1072 - val_loss: 1.7924 - val_accuracy: 0.1049\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 330s 30s/step - loss: 1.6775 - accuracy: 0.1312 - val_loss: 1.7903 - val_accuracy: 0.1434\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 325s 30s/step - loss: 1.5930 - accuracy: 0.1477 - val_loss: 1.7987 - val_accuracy: 0.1621\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 327s 30s/step - loss: 1.5334 - accuracy: 0.1666 - val_loss: 1.7634 - val_accuracy: 0.1881\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 325s 30s/step - loss: 1.4818 - accuracy: 0.1903 - val_loss: 1.6838 - val_accuracy: 0.2172\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 325s 30s/step - loss: 1.3706 - accuracy: 0.2214 - val_loss: 1.6653 - val_accuracy: 0.2238\n",
            "Epoch 7/30\n",
            "11/11 [==============================] - 320s 29s/step - loss: 1.2704 - accuracy: 0.2552 - val_loss: 1.6490 - val_accuracy: 0.2487\n",
            "Epoch 8/30\n",
            "11/11 [==============================] - 324s 29s/step - loss: 1.1728 - accuracy: 0.3141 - val_loss: 1.6386 - val_accuracy: 0.2609\n",
            "Epoch 9/30\n",
            "11/11 [==============================] - 325s 30s/step - loss: 1.0850 - accuracy: 0.3610 - val_loss: 1.5623 - val_accuracy: 0.2883\n",
            "Epoch 10/30\n",
            "11/11 [==============================] - 323s 30s/step - loss: 0.9567 - accuracy: 0.4458 - val_loss: 1.5633 - val_accuracy: 0.2994\n",
            "Epoch 11/30\n",
            "11/11 [==============================] - 327s 30s/step - loss: 0.8692 - accuracy: 0.4900 - val_loss: 1.5668 - val_accuracy: 0.3029\n",
            "Epoch 12/30\n",
            "11/11 [==============================] - 323s 30s/step - loss: 0.7812 - accuracy: 0.5330 - val_loss: 1.5000 - val_accuracy: 0.3851\n",
            "Epoch 13/30\n",
            "11/11 [==============================] - 321s 29s/step - loss: 0.7187 - accuracy: 0.5556 - val_loss: 1.5041 - val_accuracy: 0.4148\n",
            "Epoch 14/30\n",
            "11/11 [==============================] - 327s 30s/step - loss: 0.6576 - accuracy: 0.5815 - val_loss: 1.4896 - val_accuracy: 0.4137\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd0d2abc890>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "seq2seq_02.compile(\n",
        "optimizer=\"rmsprop\",\n",
        "loss=\"sparse_categorical_crossentropy\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "seq2seq_02.fit(train_ds, epochs=30, validation_data=val_ds, callbacks=callbacks)"
      ],
      "id": "9C3iAubxKS8Z"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HyGsqQ4tKUEz"
      },
      "outputs": [],
      "source": [
        "query_vocab = query_vectorization.get_vocabulary()\n",
        "query_index_lookup = dict(zip(range(len(query_vocab)), query_vocab))\n",
        "max_decoded_sentence_length = 20"
      ],
      "id": "HyGsqQ4tKUEz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg7cwVPrKWkL"
      },
      "outputs": [],
      "source": [
        "def decode_sequence_02(input_sentence):\n",
        "  tokenized_input_sentence = question_vectorization([input_sentence])\n",
        "  decoded_sentence = \"[start]\"\n",
        "  for i in range(max_decoded_sentence_length):\n",
        "    tokenized_target_sentence = query_vectorization([decoded_sentence])\n",
        "    next_token_predictions = seq2seq_02.predict([tokenized_input_sentence, tokenized_target_sentence])\n",
        "    sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
        "\n",
        "    sampled_token = query_index_lookup[sampled_token_index]\n",
        "    decoded_sentence += \" \" + sampled_token\n",
        "    if sampled_token == \"[end]\":\n",
        "      break\n",
        "  return decoded_sentence"
      ],
      "id": "mg7cwVPrKWkL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wNNqLzRGKblC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87b99b5f-6753-4b26-d904-b8737e27f71d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-1 Score on Test Dataset: 0.136778\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in test_pairs]\n",
        "query_texts = [pair[1] for pair in test_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_02(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Test Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "id": "wNNqLzRGKblC"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUjOI3LfxOiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278b371d-fe0a-4c32-99d6-5c117dfe4ab1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Show the shop addresses ordered by their opening year.\n",
            "[start] select state_name from state where state_name = ( select min ( area ) from state ); [end]\n",
            "-\n",
            "Please list the name and id of all artists that have at least 3 albums in alphabetical order.\n",
            "[start] select state_name from state where state_name = ( select max ( area ) from state where state_name = ( select\n",
            "-\n",
            "What are the invoice dates for customers with the first name Astrid and the last name Gruber?\n",
            "[start] select state_name from state where state_name = ( select max ( area ) from state where state_name = ( select\n",
            "-\n",
            "What are the duration of the longest and shortest pop tracks in milliseconds?\n",
            "[start] select state_name from state where state_name = ( select min ( area ) from state where state_name = ( select\n",
            "-\n",
            "Find the names of artists that do not have any albums.\n",
            "[start] select state_name from state where state_name = ( select min ( area ) from state where state_name = ( select\n"
          ]
        }
      ],
      "source": [
        "test_questions_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(5):\n",
        "  input_sentence = random.choice(test_questions_texts)\n",
        "  print(\"-\")\n",
        "  print(input_sentence)\n",
        "  print(decode_sequence_02(input_sentence))"
      ],
      "id": "FUjOI3LfxOiL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIpDGHZyxSJJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48b313cb-2983-4a5f-8179-f52621c5ca38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-1 Score on Validation Dataset: 0.144720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in val_pairs]\n",
        "query_texts = [pair[1] for pair in val_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_02(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Validation Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "id": "HIpDGHZyxSJJ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_qhY0vwJxYB0"
      },
      "source": [
        "# Model 3: Two Layer Bidirectional LSTM"
      ],
      "id": "_qhY0vwJxYB0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Q-HI9RNxg8V"
      },
      "outputs": [],
      "source": [
        "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
        "encoded_source = layers.Bidirectional(layers.LSTM(latent_dim), merge_mode=\"sum\")(x)\n",
        "out_encoder1, state_h_forward1, state_c_forward1, state_h_backward1, state_c_backward1 = layers.Bidirectional(layers.LSTM(latent_dim, return_sequences=True, return_state=True), merge_mode=\"sum\")(x)\n",
        "out_encoder2, state_h_forward2, state_c_forward2, state_h_backward2, state_c_backward2 = layers.Bidirectional(layers.LSTM(latent_dim, return_sequences=True, return_state=True), merge_mode=\"sum\")(out_encoder1)"
      ],
      "id": "2Q-HI9RNxg8V"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k8e_tVt-xjZc"
      },
      "outputs": [],
      "source": [
        "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
        "decoder_LSTM = layers.LSTM(latent_dim, return_sequences=True)\n",
        "\n",
        "encoder_state=[state_h_forward2, state_c_forward2]\n",
        "\n",
        "x = decoder_LSTM(x, initial_state=encoder_state)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)"
      ],
      "id": "k8e_tVt-xjZc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nnY15YY7xmEe"
      },
      "outputs": [],
      "source": [
        "seq2seq_03 = keras.Model([source, past_target], target_next_step)"
      ],
      "id": "nnY15YY7xmEe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hUJxHtMxoZh"
      },
      "outputs": [],
      "source": [
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=1),\n",
        "             ModelCheckpoint(\"seq2seq_03.keras\", save_best_only=True, monitor=\"val_accuracy\", mode='max')]"
      ],
      "id": "8hUJxHtMxoZh"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mkueJQu9xqvi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "285b2ff0-1210-4c7b-f704-3df56c9ee93e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['bidirectional_4/backward_lstm_4/lstm_cell_12/kernel:0', 'bidirectional_4/backward_lstm_4/lstm_cell_12/recurrent_kernel:0', 'bidirectional_4/backward_lstm_4/lstm_cell_12/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['bidirectional_4/backward_lstm_4/lstm_cell_12/kernel:0', 'bidirectional_4/backward_lstm_4/lstm_cell_12/recurrent_kernel:0', 'bidirectional_4/backward_lstm_4/lstm_cell_12/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss`argument?\n",
            "11/11 [==============================] - 547s 48s/step - loss: 2.3570 - accuracy: 0.1023 - val_loss: 1.7486 - val_accuracy: 0.1444\n",
            "Epoch 2/30\n",
            "11/11 [==============================] - 518s 47s/step - loss: 1.6675 - accuracy: 0.1377 - val_loss: 1.7716 - val_accuracy: 0.1514\n",
            "Epoch 3/30\n",
            "11/11 [==============================] - 525s 48s/step - loss: 1.5876 - accuracy: 0.1511 - val_loss: 1.7713 - val_accuracy: 0.1700\n",
            "Epoch 4/30\n",
            "11/11 [==============================] - 525s 48s/step - loss: 1.5353 - accuracy: 0.1716 - val_loss: 1.7373 - val_accuracy: 0.1940\n",
            "Epoch 5/30\n",
            "11/11 [==============================] - 524s 48s/step - loss: 1.4495 - accuracy: 0.1989 - val_loss: 1.6811 - val_accuracy: 0.2247\n",
            "Epoch 6/30\n",
            "11/11 [==============================] - 527s 48s/step - loss: 1.3515 - accuracy: 0.2276 - val_loss: 1.6664 - val_accuracy: 0.2176\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd0d01cc350>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "seq2seq_03.compile(\n",
        "optimizer=\"rmsprop\",\n",
        "loss=\"sparse_categorical_crossentropy\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "seq2seq_03.fit(train_ds, epochs=30, validation_data=val_ds, callbacks=callbacks)"
      ],
      "id": "mkueJQu9xqvi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMZLNi59xvDp"
      },
      "outputs": [],
      "source": [
        "query_vocab = query_vectorization.get_vocabulary()\n",
        "query_index_lookup = dict(zip(range(len(query_vocab)), query_vocab))\n",
        "max_decoded_sentence_length = 20"
      ],
      "id": "IMZLNi59xvDp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a1x5Ididxxrn"
      },
      "outputs": [],
      "source": [
        "def decode_sequence_03(input_sentence):\n",
        "  tokenized_input_sentence = question_vectorization([input_sentence])\n",
        "  decoded_sentence = \"[start]\"\n",
        "  for i in range(max_decoded_sentence_length):\n",
        "    tokenized_target_sentence = query_vectorization([decoded_sentence])\n",
        "    next_token_predictions = seq2seq_03.predict([tokenized_input_sentence, tokenized_target_sentence])\n",
        "    sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
        "\n",
        "    sampled_token = query_index_lookup[sampled_token_index]\n",
        "    decoded_sentence += \" \" + sampled_token\n",
        "    if sampled_token == \"[end]\":\n",
        "      break\n",
        "  return decoded_sentence"
      ],
      "id": "a1x5Ididxxrn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bPUHnnxxx-5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83742256-e135-462e-9ee6-347b61925119"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BLEU-1 Score on Test Dataset: 0.145675\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in test_pairs]\n",
        "query_texts = [pair[1] for pair in test_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_03(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Test Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "id": "bPUHnnxxx-5d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T4AM6xYAyBRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ec46c7c-ca50-4983-a48c-7b19f080c7f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-\n",
            "Show the album names and ids for albums that contain tracks with unit price bigger than 1.\n",
            "[start] select distinct from from where where where ( ( ( select ( select ( select ( select ( select (\n",
            "-\n",
            "What are the names and trade names of the medcines that are FDA approved?\n",
            "[start] select distinct from from where where where ( select ( select ( select ( select ( select ( select (\n",
            "-\n",
            "What are the names of enzymes who does not produce 'Heme'?\n",
            "[start] select distinct from from where where where ( select ( select ( select ( select ( select ( as (\n",
            "-\n",
            "Return the type of transaction with the highest total amount.\n",
            "[start] select distinct from from where where where ( select ( select ( select ( select ( select ( as (\n",
            "-\n",
            "What is the total and minimum enrollment of all schools?\n",
            "[start] select distinct from from where where where ( select ( select ( select ( select ( select ( as (\n"
          ]
        }
      ],
      "source": [
        "test_questions_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(5):\n",
        "  input_sentence = random.choice(test_questions_texts)\n",
        "  print(\"-\")\n",
        "  print(input_sentence)\n",
        "  print(decode_sequence_03(input_sentence))"
      ],
      "id": "T4AM6xYAyBRB"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6zY2NeAzyDxv"
      },
      "outputs": [],
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in val_pairs]\n",
        "query_texts = [pair[1] for pair in val_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_03(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Validation Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "id": "6zY2NeAzyDxv"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VnO889QxyKWz"
      },
      "source": [
        "# Model 4: Three Layer Bidirectional LSTM"
      ],
      "id": "VnO889QxyKWz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNtiKlP8yJTH"
      },
      "outputs": [],
      "source": [
        "source = keras.Input(shape=(None,), dtype=\"int64\", name=\"encoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(source)\n",
        "encoded_source = layers.Bidirectional(layers.LSTM(latent_dim), merge_mode=\"sum\")(x)\n",
        "out_encoder1, state_h_forward1, state_c_forward1, state_h_backward1, state_c_backward1 = layers.Bidirectional(layers.LSTM(latent_dim, return_sequences=True, return_state=True), merge_mode=\"sum\")(x)\n",
        "out_encoder2, state_h_forward2, state_c_forward2, state_h_backward2, state_c_backward2 = layers.Bidirectional(layers.LSTM(latent_dim, return_sequences=True, return_state=True), merge_mode=\"sum\")(out_encoder1)\n",
        "out_encoder3, state_h_forward3, state_c_forward3, state_h_backward3, state_c_backward3 = layers.Bidirectional(layers.LSTM(latent_dim, return_sequences=True, return_state=True), merge_mode=\"sum\")(out_encoder2)"
      ],
      "id": "PNtiKlP8yJTH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "irFE4W5uyemp"
      },
      "outputs": [],
      "source": [
        "past_target = keras.Input(shape=(None,), dtype=\"int64\", name=\"decoder_inputs\")\n",
        "x = layers.Embedding(vocab_size, embed_dim, mask_zero=True)(past_target)\n",
        "decoder_LSTM = layers.LSTM(latent_dim, return_sequences=True)\n",
        "\n",
        "encoder_state=[state_h_forward3, state_c_forward3]\n",
        "\n",
        "x = decoder_LSTM(x, initial_state=encoder_state)\n",
        "x = layers.Dropout(0.5)(x)\n",
        "target_next_step = layers.Dense(vocab_size, activation=\"softmax\")(x)"
      ],
      "id": "irFE4W5uyemp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBjuCjYpygzl"
      },
      "outputs": [],
      "source": [
        "seq2seq_04 = keras.Model([source, past_target], target_next_step)"
      ],
      "id": "YBjuCjYpygzl"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofYdXe96yjwG"
      },
      "outputs": [],
      "source": [
        "callbacks = [EarlyStopping(monitor='val_accuracy', patience=1),\n",
        "             ModelCheckpoint(\"seq2seq_04.keras\", save_best_only=True, monitor=\"val_accuracy\", mode='max')]"
      ],
      "id": "ofYdXe96yjwG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OaHLuBqSymJF"
      },
      "outputs": [],
      "source": [
        "seq2seq_04.compile(\n",
        "optimizer=\"rmsprop\",\n",
        "loss=\"sparse_categorical_crossentropy\",\n",
        "metrics=[\"accuracy\"])\n",
        "\n",
        "seq2seq_04.fit(train_ds, epochs=30, validation_data=val_ds, callbacks=callbacks)"
      ],
      "id": "OaHLuBqSymJF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGDPPRCKyoYb"
      },
      "outputs": [],
      "source": [
        "query_vocab = query_vectorization.get_vocabulary()\n",
        "query_index_lookup = dict(zip(range(len(query_vocab)), query_vocab))\n",
        "max_decoded_sentence_length = 20"
      ],
      "id": "SGDPPRCKyoYb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GjeMt7LCyqU5"
      },
      "outputs": [],
      "source": [
        "def decode_sequence_04(input_sentence):\n",
        "  tokenized_input_sentence = question_vectorization([input_sentence])\n",
        "  decoded_sentence = \"[start]\"\n",
        "  for i in range(max_decoded_sentence_length):\n",
        "    tokenized_target_sentence = query_vectorization([decoded_sentence])\n",
        "    next_token_predictions = seq2seq_04.predict([tokenized_input_sentence, tokenized_target_sentence])\n",
        "    sampled_token_index = np.argmax(next_token_predictions[0, i, :])\n",
        "\n",
        "    sampled_token = query_index_lookup[sampled_token_index]\n",
        "    decoded_sentence += \" \" + sampled_token\n",
        "    if sampled_token == \"[end]\":\n",
        "      break\n",
        "  return decoded_sentence"
      ],
      "id": "GjeMt7LCyqU5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AqEwE3evysme"
      },
      "outputs": [],
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in test_pairs]\n",
        "query_texts = [pair[1] for pair in test_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_04(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Test Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "id": "AqEwE3evysme"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m14SLBVuyu6J"
      },
      "outputs": [],
      "source": [
        "test_questions_texts = [pair[0] for pair in test_pairs]\n",
        "for _ in range(5):\n",
        "  input_sentence = random.choice(test_questions_texts)\n",
        "  print(\"-\")\n",
        "  print(input_sentence)\n",
        "  print(decode_sequence_04(input_sentence))"
      ],
      "id": "m14SLBVuyu6J"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XwlwciZkyy2W"
      },
      "outputs": [],
      "source": [
        "actual, predicted = list(), list()\n",
        "question_texts = [pair[0] for pair in val_pairs]\n",
        "query_texts = [pair[1] for pair in val_pairs]\n",
        "for i in range(len(question_texts)):\n",
        "  input_sentence = question_texts[i]\n",
        "  output_sentence = query_texts[i]\n",
        "  y_pred= decode_sequence_04(input_sentence)\n",
        "  actual.append(output_sentence)\n",
        "  predicted.append(y_pred)\n",
        "    \n",
        "# calcuate BLEU score\n",
        "print(\"BLEU-1 Score on Validation Dataset: %f\" % corpus_bleu(actual, predicted, weights=(1.0, 0, 0, 0)))"
      ],
      "id": "XwlwciZkyy2W"
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "CE -888 Assessment-2.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}